{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "import Bio.PDB.PDBParser\n",
    "from Bio.PDB.Polypeptide import protein_letters_3to1\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_point_clouds_N_Ca_C_O(pdb_filename: str, cath_id: str):\n",
    "  # https://stackoverflow.com/questions/14463277/how-to-disable-python-warnings\n",
    "  import warnings\n",
    "  warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "  pdb_parser = Bio.PDB.PDBParser()\n",
    "  structure = pdb_parser.get_structure(cath_id, pdb_filename)\n",
    "\n",
    "  # Expect only one model per structure.\n",
    "  assert(len(structure) == 1)\n",
    "\n",
    "  points_N = []\n",
    "  points_Ca = []\n",
    "  points_C = []\n",
    "  points_O = []\n",
    "\n",
    "  for residue in structure.get_residues():\n",
    "    for a in residue.get_atoms():\n",
    "      name = a.get_fullname().strip()\n",
    "\n",
    "      if name == 'N':\n",
    "        points_N.append(a.get_coord())\n",
    "      elif name == 'CA':\n",
    "        points_Ca.append(a.get_coord())\n",
    "      elif name == 'C':\n",
    "        points_C.append(a.get_coord())\n",
    "      elif name == 'O':\n",
    "        points_O.append(a.get_coord())\n",
    "\n",
    "  return [torch.Tensor(l) for l in [points_N, points_Ca, points_C, points_O]]\n",
    "\n",
    "\n",
    "def center_and_scale_unit_sphere(points: torch.Tensor) -> torch.Tensor:\n",
    "  mu = points.mean(dim=0)\n",
    "  vmax, _ = points.max(dim=0)\n",
    "  vmin, _ = points.min(dim=0)\n",
    "  max_dim = (vmax - vmin).norm()\n",
    "  points = 2 * (points - mu) / max_dim\n",
    "  return points + 0.5\n",
    "\n",
    "\n",
    "def center_and_scale_unit_box(points: torch.Tensor) -> torch.Tensor:\n",
    "  \"\"\"\n",
    "  Scales all of the points uniformly so that they are in the range [0, 1].\n",
    "  \"\"\"\n",
    "  mu = points.mean(dim=0)\n",
    "  # Min and max corners of the bounding box.\n",
    "  vmax = torch.Tensor([points[:,0].amax(), points[:,1].amax(), points[:,2].amax()])\n",
    "  vmin = torch.Tensor([points[:,0].amin(), points[:,1].amin(), points[:,2].amin()])\n",
    "  sf = 1.0 / (vmax - vmin + 1).max() # largest bbox dimension\n",
    "  centered = (points - mu)\n",
    "  return (centered * sf) + 0.5\n",
    "\n",
    "\n",
    "def create_occupancy_grid(points: torch.Tensor, G: int = 100) -> torch.Tensor:\n",
    "  \"\"\"Create a 3D occupancy grid from a collection of poins.\"\"\"\n",
    "  pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(points))\n",
    "  voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size=(1/G))\n",
    "  voxels = voxel_grid.get_voxels()\n",
    "  indices = np.stack(list(vx.grid_index for vx in voxels))\n",
    "\n",
    "  O = torch.zeros((G, G, G))\n",
    "\n",
    "  for idx in indices:\n",
    "    O[tuple(idx)] += 1\n",
    "\n",
    "  return O\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cath_id = \"1a0gA02\"\n",
    "pdb_filename = f\"../data/pdb_share/16pkA02.pdb\"\n",
    "points_N, points_Ca, points_C, points_O = extract_point_clouds_N_Ca_C_O(pdb_filename, cath_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_N_cent = center_and_scale_unit_box(points_N)\n",
    "points_C_cent = center_and_scale_unit_box(points_C)\n",
    "points_Ca_cent = center_and_scale_unit_box(points_Ca)\n",
    "points_O_cent = center_and_scale_unit_box(points_O)\n",
    "\n",
    "O_N = create_occupancy_grid(points_N_cent, G=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_N_cent.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the points.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_point_cloud(points_C, points_N, points_Ca, points_O):\n",
    "  fig = plt.figure()\n",
    "  ax = plt.axes(projection='3d')\n",
    "\n",
    "  ax.scatter(points_C[:,0], points_C[:,1], points_C[:,2], 'red')\n",
    "  ax.scatter(points_N[:,0], points_N[:,1], points_N[:,2], 'green')\n",
    "  ax.scatter(points_Ca[:,0], points_Ca[:,1], points_Ca[:,2], 'gray')\n",
    "  ax.scatter(points_O[:,0], points_O[:,1], points_O[:,2], 'red')\n",
    "\n",
    "plot_point_cloud(points_C, points_N, points_Ca, points_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the occupancy grid.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "G = 1000\n",
    "points = O_N.nonzero() / G\n",
    "\n",
    "xline = points[:,0]\n",
    "yline = points[:,1]\n",
    "zline = points[:,2]\n",
    "ax.scatter(xline, yline, zline, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = o3d.utility.Vector3dVector(points_Ca_cent)\n",
    "pcd = o3d.geometry.PointCloud(v)\n",
    "\n",
    "grid_dim = 100\n",
    "\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(\n",
    "  pcd, voxel_size=1/grid_dim\n",
    ")\n",
    "voxels = voxel_grid.get_voxels()  # returns list of voxels\n",
    "indices = np.stack(list(vx.grid_index for vx in voxels))\n",
    "# colors = np.stack(list(vx.color for vx in voxels))\n",
    "\n",
    "O = torch.zeros((grid_dim, grid_dim, grid_dim))\n",
    "# O[[tuple(idx) for idx in indices]] = 1\n",
    "\n",
    "for idx in indices:\n",
    "#   print(idx)\n",
    "  O[tuple(idx)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = torch.zeros((3, 3, 3))\n",
    "\n",
    "O[torch.LongTensor([\n",
    "  [0, 0, 1],\n",
    "  [0, 0, 0],\n",
    "  [0, 0, 2]\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concat([O.unsqueeze(-1), O.unsqueeze(-1)], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from gvpgnn.datasets import ProteinVoxelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ProteinVoxelDataset(\"../data/challenge_test_set/\", None, \"cpu\", voxel_grid_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(d):\n",
    "  print(i, data[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cath-proteins-q1ibxFh1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
